{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. Ch 03. Probabilistic Perspective - 05. 수식 MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLE(NLL) and Cross Entropy Loss\n",
    "네거티브 로그 라이클리후드(NLL)를 최소화하는 MLE는 크로스 엔트로피를 최소화하는 것과 같다\n",
    "\n",
    "그동안 분류에서 소프트맥스를 쓰고 크로스엔트로피 로스를 써서 최적화를 수행했다.\n",
    "그 과정이 알고 보면 MLE를 하기 위한 과정이었던 것이다.\n",
    "뉴럴 네트워크는 세타라고 하는 레이어 웨이트들을 포함하는 세타라고 하는 분포 함수의 파라미터를 가지고 있는데,\n",
    "내가 수집한 데이터를 잘 설명하기 위한 파라미터를 찾는 과정을 하고 있었던 것이다 MLE를 통해서.\n",
    "그렇기 때문에 크로스 엔트로피를 수행했다고 할 수 있는 것이다. 그래서 크로스 엔트로피를 분류에 써온 것이다.\n",
    "왜? MLE를 하려고"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14. Ch 03. Probabilistic Perspective - 06. Maximum A Posterior (MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "베이즈 정리\n",
    "p(h|D) = P(D|h)P(h) /  P(D)\n",
    "사후확률(Posterior) = 가능도 혹은 우도(Likelihood)*사전확률(Prior) / 정규화상수 혹은 증거(Evidence)\n",
    "h: hypothesis , D:data\n",
    "그전에는 가능도를 최대화해서 h를 찾았지만,\n",
    "여기선 사후확률을 최대화해서 h를 찾는 방법을 알아보갰다\n",
    "\n",
    "Maximum A Posterior (MAP) Estimation Example\n",
    "포스테리어를 최대화함으로 h를 찾는 방법\n",
    "절도 사건의 범인은 발자국을 남겼다.\n",
    "신발 사이즈 240일 때, 범인은 남지일까? 여자일까?\n",
    "P(y|X = 240)\n",
    "지인 중에 신발 사이즈가 240이었던 사람들을 떠올려보자\n",
    "여자 중에 많을까 남자중에 많을까\n",
    "P(X = 240|y)\n",
    "그런데 범행 장소가 군부대라면?\n",
    "P(y=male) > P(y = female)\n",
    "수식적으로 살펴봤을 때는 가능도에 사전확률을 곱한 값을 최대화하는 것과 같다\n",
    "\n",
    "Bayesian vs Frequentist\n",
    "베이지안 관점\n",
    "파라미터 또한 랜덤 베리어블이며, 프라이어 분포를 따를 것\n",
    "미래의 uncertainty까지 고려\n",
    "Prior에 대한 가정이 필요\n",
    "Frequentist 관점\n",
    "파라미터는 최적화의 대상\n",
    "현재까지의 정보를 바탕으로 추정\n",
    "오버피팅에 취약함\n",
    "\n",
    "여기까지만 보면 베이지안 관점이 더 좋아보일 수 있지만 딥러닝에서 베이지안이 아직까진 큰 성과를 거두지 못하고 있다.\n",
    "\n",
    "요약\n",
    "MAP를 통해 우리는 포스테리어를 최대화하는 가설을 찾을 수 있음\n",
    "마찬가지로 주어진 데이터셋에 대한 포스테리어를 최대화하는 파라미터 세타를 찾을 수 있음\n",
    "베이지안 관점에서는 프라이어에 대한 가정을 통해, 앞으로의 uncertainty까지 고려\n",
    "이를 통해 오버피팅 등의 문제도 해결할 수 있음\n",
    "베이지안 딥러닝에 대한 다양한 시도들이 이어지고 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15. Ch 03. Probabilistic Perspective - 07. KL-Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "쿨벡라이블러 다이버전스(Kullback-Leibler Divergence)\n",
    "두 분포 사이의 다름을 측정할 수 있다.\n",
    "KLD는 불균형, 비대칭을 나타내는 척도. 거리가 아니다.\n",
    "두 분포가 얼마나 다르냐를 나타냄\n",
    "KL(p||q) \n",
    "p 관점에서 p 분포와 q 분포의 다름을 측정\n",
    "KLD는 두 분포가 덜 가까울수록 더 큰 값을 가지게 된다\n",
    "비슷할수록 작은 값을 리턴. 최저 0이 된다. 완전 똑같다고 할 때.\n",
    "\n",
    "KLD가 0이 되면 딥뉴럴네트워크 잘 최적화한 것\n",
    "KLD를 최소화하는 방향으로도 딥뉴럴네트워크를 최적화할 수 있다.\n",
    "\n",
    "KLD를 로스함수로 삼아서 이를 최소화해주는 세타를 찾으면 우리가 원하는 세타가 되는 것\n",
    "찾을 때 그레디언트 디센트로 찾으면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16. Ch 03. Probabilistic Perspective - 08. Information & Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Information\n",
    "본디, 통신이나 압축을 위해 주로 다루어지던 분야\n",
    "Representation learning에 관해서 다루다보니 자연스럽게 연결됨\n",
    "불확실성(Uncertainty)을 나타내는 값\n",
    "I(X) = -log P(X)\n",
    "불확실하다면 확률이 낮다. 확률이 낮을수록 정보 값은 높다고 할 수 있다.\n",
    "정보가 높다고하면 불확실, 정보가 낮으면 확실하다고 말할 수 있음\n",
    "\n",
    "예를 들면\n",
    "올 여름 대한민국의 평균 여름 기온은 26도입니다.(일반적인 정보지만 확률은 높다)\n",
    "올 여름 대한민국의 평균 여름 기온은 8도입니다.(엄청난 정보 하지만 확률은 낮다)\n",
    "내일 아침 해는 동쪽 하늘에서 뜹니다.\n",
    "내일 아침 해는 서쪽 하늘에서 뜹니다.\n",
    "누구나 아는 것은 정보가 될 수 없다.\n",
    "확률이 낮은 정보일수록 엄청난 정보량을 가지고 있다\n",
    "\n",
    "엔트로피\n",
    "만들어놓고 보니 물리의 엔트로피와 비슷. 그래서 이름을 엔트로피로 지음\n",
    "정보량의 기대값(평균)\n",
    "분포의 평균적인 Uncertainty를 나타내는 값\n",
    "분포의 형태를 예측해 볼 수 있음\n",
    "H(P) = -Ex~P(x)[logP(x)]\n",
    "엔트로피가 클수록 플랫한 형태, 작을수록 샤프한 형태일 것으로 예측할 수 있다\n",
    "엔트로피가 작을수록(한 지점에 모여있는 형태) 불확실성이 낮다.\n",
    "엔트로피가 클수록(플랫한 형태) 불확실성이 높다.\n",
    "엔트로피 값을 가지고 분포의 형태를 예측할 수 있다.\n",
    "항상 엔트로피는 높은 방향으로 흐른다.\n",
    "\n",
    "Cross Entropy\n",
    "분포 P의 관점에서 본 분포 Q의 정보량의 평균\n",
    "두 분포가 비슷할수록 작은 값을 가진다.\n",
    "H(P, Q) = - Ex~P(x)[log Q(x)]\n",
    "P(x)에서 뽑아낸 x를 집어넣은 함수 -log Q(x)에서 샘플링을 계속해서 평균을 내주겠다는 것으로 해석할 수 있음.\n",
    "두 분포가 비슷할수록 크로스엔트로피는 더 작아지게 된다.\n",
    "그렇기 때문에 우리는 크로스엔트로피로 딥뉴럴네트워크를 최적화한 것.\n",
    "우리는  세타라는 파라미터를 가진 확률분포함수를 그라운드트루스 확률분포 P에 가깝게 만들고 싶다\n",
    "두 함수가 가까워질수록 크로스엔트로피가 작아진다.\n",
    "우리는 이 두 분포의 비슷한 정도를 크로스엔트로피로 측정하고\n",
    "크로스 엔트로피를 최소화하기 위해 그레디언트 디센트를 했던 것\n",
    "그레디언트 디센트를 하기 위해서는 백 프로퍼게이션을 해야한다. 세타로 미분해서\n",
    "이렇게 이야기가 이어진다\n",
    "\n",
    "DNN Optimization using Cross Entropy\n",
    "분류 문제에서 Cross Entropy Loss를 사용해 최소화\n",
    "NLL을 최소화한 MLE는 크로스엔트로피와 수식이 같다, 그래서 크로스엔트로피를 사용한다고 설명했었는데\n",
    "사실 정보량 관점에서 봤을 때 크로스엔트로피를 미니마이즈 하는 것도 결국 같은 문제라는 것.\n",
    "\n",
    "KL-Divergence and Cross Entropy\n",
    "KLD와 교차 엔트로피를 세타로 미분하면 같다.\n",
    "\n",
    "요약\n",
    "목표: 확률분포 P(x)로부터 수집한 데이터셋 D를 통해, 확률 분포 함수 P(y|x)를 근사하고 싶다.\n",
    "확률 분포 함수 신경망 P세타(y|x)를 통해 이를 수행하자.\n",
    "KL-Divergence(또는 크로스 엔트로피)가 최소가 되도록 그레디언트 디센트 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 17. Ch 03. Probabilistic Perspective - 09. Appendix - MSE Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE with Probablilistic Perspective\n",
    "크로스 엔트로피는 분류에서만 쓰인다\n",
    "회귀에서는 MSE 쓴다.\n",
    "MSE도 크로스 엔트로피, MLE, KLD와 똑같이 확률적 관점에서 해석해볼 수 있다. 다르지 않다.\n",
    "뉴럴네트워크의 출력이 가우시안 분포를 따른다고 가정했을 때 MSE를 썼다.\n",
    "이전의 분류는 멀티노미얼 디스트리뷰션을 따르게 된다. 이 경우에는 교차 엔트로피를 써서 최소화하는 게 맞다.\n",
    "가우시안 PDF\n",
    "MLE with 그레디언트 디센트\n",
    "\n",
    "Get gradient of NLL\n",
    "MSE로스도 마찬가지로 확률분포라고 가정했어도 여전히 워킹한다는 것\n",
    "분류는 확률분포가 맞고 회귀는 확률분포로 취급 안 해 이게 아니라\n",
    "분류에서는 다항분포로 확률분포를 가정한 것이고 회귀 태스크에서는 가우시안 분포로 확률분포를 가정하면\n",
    "여전히 똑같은 MLE에 넣었을 떄 우리는 MSE 로스를 미니마이즈 한 것과 똑같은 수식을 얻을 수 있다는 것.\n",
    "단 시그마는 무시하고 우리는 뮤에 대해서만 관심을 가지고 있다 가우시안 분포에서.\n",
    "결론은 뉴럴 네트워크는 단순히 함수를 모사하는 게 아니라 확률분포를 모사한다는 것.\n",
    "왜? 뉴럴 네트워크 또한 확률 분포이기 때문에."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18. Ch 03. Probabilistic Perspective - 10. 정리하며"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Before this chapter\n",
    "우리의 목표는\n",
    "우리의 세계(머릿속)에 존재하는 가상의 함수를 모사하자\n",
    "주어진 입력(x)에 대해서 원하는 출력(y)을 반환하도록, 손실함수를 최소화하는 파라미터(세타)를 찾자.\n",
    "그레디언트 디센트를 수행하기 위해 역전파(DNN은 레이어가 깊어 한 번에 미분하기 어렵기 때문)를 수행하자.\n",
    "\n",
    "after this chapter\n",
    "함수를 배우자(deterministic target 값을 예측) -> 확률 분포 함수를 배우자(수학적으로 좀 더 설명 가능함, 불확실성까지 학습)\n",
    "\n",
    "우리의 목표는\n",
    "우리의 세계(머릿속)에 존재하는 가상의 확률분포함수를 모사하자\n",
    "확률분포P(x)에서 수집한 입력 데이터 x에 대해서 원하는 조건부 확률 분포 P(y|x) 또는 샘플링한 출력 데이터 y를 반환하도록,\n",
    "손실함수를 최소화하는 확률 분포 함수의 파라미터(세타)를 찾자.\n",
    "그래서 MLE를 사용 -> NLL을 최소화하는 것과 같다\n",
    "-> 크로스엔트로피 최소화와 수식 같다(정보량 관점에서도 크로스 엔트로피를 최소화하는 것은 두 분포를 비슷하게 만드는 거였다)\n",
    "이런 것들을 최소화하기 위해 그레디언트 디센트 사용, 이를 수행하기 위해 역전파를 수행하자."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
